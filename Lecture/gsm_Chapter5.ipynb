{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvVAWhjF0/lVgSDv8bu4hz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[코드 gsm 5-1] 3초 간격으로 날짜와 시간 정보 크롤링"],"metadata":{"id":"czeyJpFzWYxj"}},{"cell_type":"code","source":["import time\n","import datetime\n","count = 10\n","while count > 0:\n","  count -= 1\n","  now = datetime.datetime.now() + datetime.timedelta(hours=9)\n","  yymmdd = now.strftime('%Y-%m-%d')\n","  hhmmss = now.strftime('%H:%M:%S')\n","  time_list = [yymmdd, hhmmss]\n","  print(time_list)\n","\n","  time.sleep(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2p6AuTR7XTlK","executionInfo":{"status":"ok","timestamp":1727674533838,"user_tz":-540,"elapsed":30430,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"50252db8-5e24-4bef-9165-5a4ba5848dd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['2024-09-30', '14:35:03']\n","['2024-09-30', '14:35:06']\n","['2024-09-30', '14:35:09']\n","['2024-09-30', '14:35:12']\n","['2024-09-30', '14:35:15']\n","['2024-09-30', '14:35:18']\n","['2024-09-30', '14:35:21']\n","['2024-09-30', '14:35:24']\n","['2024-09-30', '14:35:27']\n","['2024-09-30', '14:35:30']\n"]}]},{"cell_type":"markdown","source":["[코드 gsm 5-2] 3초 간격으로 날짜와 시간 정보 파일에 저장"],"metadata":{"id":"fG-UL8M_amGY"}},{"cell_type":"code","source":["import csv\n","import time\n","import datetime\n","\n","# CSV 파일을 UTF-8 인코딩으로 저장\n","csvName = 'gsm_datetime.csv'\n","\n","f= open(csvName, 'w', newline='', encoding='utf-8-sig')\n","csvWriter = csv.writer(f)\n","csvWriter.writerow(['연월일', '시분초'])\n","\n","count = 10\n","while count > 0:\n","  count -= 1\n","  now = datetime.datetime.now() + datetime.timedelta(hours=9)\n","  yymmdd = now.strftime('%Y-%m-%d')\n","  hhmmss = now.strftime('%H:%M:%S')\n","  time_list = [yymmdd, hhmmss]\n","\n","  # CSV 파일에 계속 추가하기\n","  f= open(csvName, 'a', newline='', encoding='utf-8-sig')\n","  csvWriter = csv.writer(f)\n","  csvWriter.writerow(time_list)\n","  time.sleep(3)"],"metadata":{"id":"Q9MCD-LHbeQL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[코드 gsm 5-3] 속초 날씨 크롤러"],"metadata":{"id":"9bynYbIkbsqX"}},{"cell_type":"code","source":["import time\n","import datetime\n","import bs4\n","import urllib.request\n","\n","nateUrl = \"https://news.nate.com/weather?areaCode=11D20401\"\n","\n","count = 5\n","while count > 0 :\n","  count -= 1\n","\n","  htmlObject = urllib.request.urlopen(nateUrl)\n","  webPage = htmlObject.read()\n","\n","  bsObject = bs4.BeautifulSoup(webPage, 'html.parser')\n","  tag = bsObject.find('div', {'class': 'right_today'})\n","\n","  temper = tag.find('p', {'class': 'celsius'}).text\n","  humi = tag.find('p', {'class': 'humidity'}).text\n","\n","  now = datetime.datetime.now()\n","  yymmdd = now.strftime('%Y-%m-%d')\n","  hhmmss = now.strftime('%H:%M:%S')\n","\n","  weather_list = [yymmdd, hhmmss, temper, humi]\n","  print(weather_list )\n","\n","  time.sleep(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAKfOhALcx2l","executionInfo":{"status":"ok","timestamp":1727674991453,"user_tz":-540,"elapsed":32874,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"8145ad85-81e5-459c-a718-2705be7a98a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['2024-09-30', '05:42:40', '25℃', '습도63%']\n","['2024-09-30', '05:42:46', '25℃', '습도63%']\n","['2024-09-30', '05:42:53', '25℃', '습도63%']\n","['2024-09-30', '05:42:59', '25℃', '습도63%']\n","['2024-09-30', '05:43:05', '25℃', '습도63%']\n"]}]},{"cell_type":"markdown","source":["[코드 gsm 5-4] 속초 날씨 파일로 저장"],"metadata":{"id":"ML1DHjSxc8De"}},{"cell_type":"code","source":["import csv\n","import time\n","import datetime\n","import bs4\n","import urllib.request\n","\n","csvName = 'gsm_sokcho_weather1.csv'\n","nateUrl = \"https://news.nate.com/weather?areaCode=11D20401\"\n","\n","count = 5\n","while count > 0 :\n","  count -= 1\n","\n","  htmlObject = urllib.request.urlopen(nateUrl)\n","  webPage = htmlObject.read()\n","\n","  bsObject = bs4.BeautifulSoup(webPage, 'html.parser')\n","  tag = bsObject.find('div', {'class': 'right_today'})\n","\n","  temper = tag.find('p', {'class': 'celsius'}).text\n","  humi = tag.find('p', {'class': 'humidity'}).text\n","\n","  now = datetime.datetime.now()\n","  yymmdd = now.strftime('%Y-%m-%d')\n","  hhmmss = now.strftime('%H:%M:%S')\n","\n","  weather_list = [yymmdd, hhmmss, temper, humi]\n","\n","  f= open(csvName, 'a', newline='', encoding='utf-8-sig')\n","  csvWriter = csv.writer(f)\n","  csvWriter.writerow(weather_list)\n","\n","  time.sleep(5)"],"metadata":{"id":"f-wqPCcJdOCQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[코드 gsm 5-5] 순위별 책명과 저자명 추출"],"metadata":{"id":"KdRlDZHpdWtH"}},{"cell_type":"code","source":["import bs4\n","import urllib.request\n","\n","## 함수 선언 부분 ##\n","def gsm_getBookInfo(book_tag) :\n","  names = book_tag.find(\"div\", {\"class\":\"goods_name\"})\n","  bookName = names.find(\"a\").text\n","  auths = book_tag.find(\"span\", {\"class\":\"goods_auth\"})\n","  bookAuth = auths.find(\"a\").text\n","  return[bookName, bookAuth]\n","\n","## 전역 변수 부분 ##\n","bookUrl = \"http://www.yes24.com/24/Category/Display/001001046001?ParamSortTp=05&PageNumber=1\"\n","\n","## 메인 코드 부분 ##\n","htmlObject = urllib.request.urlopen(bookUrl)\n","webPage = htmlObject.read()\n","bsObject = bs4.BeautifulSoup(webPage,'html.parser')\n","\n","tag = bsObject.find('ul', {'class':'clearfix'})\n","all_books = tag.findAll('div', {'class':'goods_info'})\n","\n","for book in all_books:\n","  print(gsm_getBookInfo(book))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XTR-74Mdhul","executionInfo":{"status":"ok","timestamp":1727675264314,"user_tz":-540,"elapsed":6943,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"4498bb79-c7cf-4f48-a9ad-2bcd146a8a59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['언젠가 우리가 같은 별을 바라본다면', '차인표']\n","['모순', '양귀자']\n","['영원한 천국 ', '정유정']\n","['이중 하나는 거짓말', '김애란']\n","['구의 증명', '최진영']\n","['불편한 편의점', '김호연']\n","['황금종이 1', '조정래']\n","['황금종이 2', '조정래']\n","['작별하지 않는다', '한강']\n","['나의 돈키호테', '김호연']\n","['불편한 편의점 2', '김호연']\n","['아주 희미한 빛으로도', '최은영']\n","['홍학의 자리', '정해연']\n","['파견자들', '김초엽']\n","['빛이 이끄는 곳으로', '백희성']\n","['메리골드 마음 세탁소', '윤정은']\n","['아버지의 해방일지', '정지아']\n","['시한부', '백은별']\n","['회색 인간', '김동식']\n","['소년이 온다', '한강']\n"]}]},{"cell_type":"markdown","source":["[코드 gsm 5-6] 순위별 책명과 저자명 추출 파일로 저장"],"metadata":{"id":"9qCqtECleFBE"}},{"cell_type":"code","source":["import bs4\n","import urllib.request\n","\n","## 함수 선언 부분 ##\n","def gsm_getBookInfo(book_tag) :\n","  names = book_tag.find(\"div\", {\"class\": \"goods_name\"})\n","  bookName = names.find(\"a\").text\n","  auths = book_tag.find(\"span\", {\"class\": \"goods_auth\"})\n","  bookAuth = auths.find(\"a\").text\n","  return [bookName, bookAuth]\n","\n","## 전역 변수 부분 ##\n","csvName = 'gsm_book1.csv'\n","bookUrl = \"http://www.yes24.com/24/Category/Display/001001046001?ParamSortTp=05&PageNumber=1\"\n","\n","## 메인 코드 부분 ##\n","htmlObject = urllib.request.urlopen(bookUrl)\n","webPage = htmlObject.read()\n","bsObject = bs4.BeautifulSoup(webPage, 'html.parser')\n","\n","tag = bsObject.find('ul', {'class': 'clearfix'})\n","all_books = tag.findAll('div', {'class': 'goods_info'})\n","\n","f=open(csvName, 'a', newline='', encoding='utf-8-sig')\n","csvWriter = csv.writer(f)\n","\n","for book in all_books :\n","  csvWriter.writerow(gsm_getBookInfo(book))"],"metadata":{"id":"pxwd4jKgeN2L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[코드 gsm 5-7] 영화 순위 추출"],"metadata":{"id":"KckeM1GLegeE"}},{"cell_type":"code","source":["import bs4\n","import urllib.request\n","\n","## 함수 선언 부분 ##\n","def gsm_getMovieInfo(movie_tag) :\n","  no = movie_tag.find('div', {'class': 'box-image'})\n","  movieNo = no.find('strong').text\n","  mName = movie_tag.find('div', {'class': 'box-contents'})\n","  movieName = mName.find('a').text\n","  return [movieNo, movieName]\n","\n","## 전역 변수 부분 ##\n","bookUrl = \"http://www.cgv.co.kr/movies/?lt=1&ft=0\"\n","\n","## 메인 코드 부분 ##\n","htmlObject = urllib.request.urlopen(bookUrl)\n","webPage = htmlObject.read()\n","bsObject = bs4.BeautifulSoup(webPage,'html.parser')\n","\n","tag = bsObject.find('div',{'class':'sect-movie-chart'})\n","all_movies = tag.findAll('li')\n","\n","for movie in all_movies:\n","  print(gsm_getMovieInfo(movie))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qo7FQ_zJep2F","executionInfo":{"status":"ok","timestamp":1727676266571,"user_tz":-540,"elapsed":2696,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"b3c0da67-20d0-4163-c89f-4296de06e2ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['No.1', '\\n조커-폴리 아 되\\n']\n","['No.2', '\\n대도시의 사랑법\\n']\n","['No.3', '\\n베테랑2\\n']\n","['No.4', '\\n6시간 후 너는 죽는다\\n']\n","['No.5', '\\n임영웅ㅣ아임 히어로 더 스타디움\\n']\n","['No.6', '\\n와일드 로봇\\n']\n","['No.7', '\\n트랜스포머 ONE\\n']\n","['No.8', '\\n브레드이발소-빵스타의 탄생\\n']\n","['No.9', '\\n타인의 삶\\n']\n","['No.10', '\\n명탐정 코난-시한장치의 마천루\\n']\n","['No.11', '\\n비긴 어게인\\n']\n","['No.12', '\\n더 커버넌트\\n']\n","['No.13', '\\n정국: 아이 엠 스틸\\n']\n","['No.14', '\\n러브 라이브! 더 스쿨 아이돌 무비\\n']\n","['No.15', '\\n극장총집편 봇치 더 록! 후편\\n']\n","['No.16', '\\n재즈처럼 더 무비\\n']\n","['No.17', '\\n극장판 블루 록 -에피소드 나기-\\n']\n","['No.18', '\\n사랑의 하츄핑\\n']\n","['No.19', '\\n태용: 티와이 트랙 인 시네마\\n']\n"]}]},{"cell_type":"markdown","source":["[코드 gsm 5-8] 영화 순위 파일로 저장"],"metadata":{"id":"pr2aNRcPhqXe"}},{"cell_type":"code","source":["import bs4\n","import urllib.request\n","import csv\n","\n","## 함수 선언 부분 ##\n","def gsm_getMovieInfo(movie_tag) :\n","  no = movie_tag.find('div', {'class': 'box-image'})\n","  movieNo = no.find('strong').text\n","  mName = movie_tag.find('div', {'class': 'box-contents'})\n","  movieName = mName.find('a').text\n","  return [movieNo, movieName]\n","\n","## 전역 변수 부분 ##\n","csvName = 'gsm_movie1.csv'\n","bookUrl = \"http://www.cgv.co.kr/movies/?lt=1&ft=0\"\n","\n","## 메인 코드 부분 ##\n","htmlObject = urllib.request.urlopen(bookUrl)\n","webPage = htmlObject.read()\n","bsObject = bs4.BeautifulSoup(webPage, 'html.parser')\n","\n","tag = bsObject.find('div',{'class':'sect-movie-chart'})\n","all_movies = tag.findAll('li')\n","\n","f= open(csvName, 'a', newline='', encoding='utf-8-sig')\n","csvWriter = csv.writer(f)\n","\n","for movie in all_movies :\n","  csvWriter.writerow(gsm_getMovieInfo(movie))"],"metadata":{"id":"V-SUQXdsh3DR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[코드 gsm 5-9] 6초 간격으로 날짜와 시간 정보를 크롤링  \n","(가) : count = 3  \n","(나) : time.sleep(6)  "],"metadata":{"id":"S_myM_KyiHUZ"}},{"cell_type":"code","source":["import time\n","import datetime\n","\n","count = 3\n","yymmdd_start = now.strftime('%H:%M:%S')\n","\n","while count > 0:\n","  count -= 1\n","\n","  now = datetime.datetime.now() + datetime.timedelta(hours=9)\n","  yymmdd = now.strftime('%Y-%m-%d')\n","  hhmmss = now.strftime('%H:%M:%S')\n","\n","  time_list = [yymmdd, hhmmss]\n","  print(time_list)\n","\n","  time.sleep(6) #시간간격을 조정할 때 사용함"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJpgZlGJilim","executionInfo":{"status":"ok","timestamp":1727676605547,"user_tz":-540,"elapsed":18417,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"e06ceafd-f145-43b3-a095-8778fa1375ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['2024-09-30', '15:09:47']\n","['2024-09-30', '15:09:53']\n","['2024-09-30', '15:09:59']\n"]}]},{"cell_type":"markdown","source":["[코드 gsm 5-10] 강수량과 풍속 크롤링  \n","(가) : 'p'  \n","(나) : \\{'class':'rainfall'}  \n","(다) : 'p'  \n","(라) : \\{'class':'wind'}  "],"metadata":{"id":"jwdl6l-zjSU6"}},{"cell_type":"code","source":["import time\n","import datetime\n","import bs4\n","import urllib.request\n","\n","nateUrl = \"https://news.nate.com/weather?areaCode=11D20401\"\n","\n","count = 5\n","while count > 0 :\n","  count -= 1\n","\n","  htmlObject = urllib.request.urlopen(nateUrl)\n","  webPage = htmlObject.read()\n","  bsObject = bs4.BeautifulSoup(webPage, 'html.parser')\n","\n","  tag = bsObject.find('div', {'class': 'right_today'})\n","  rain = tag.find('p',{'class':'rainfall'}).text\n","  wind = tag.find('p',{'class':'wind'}).text\n","\n","  now = datetime.datetime.now() + datetime.timedelta(hours=9)\n","  yymmdd = now.strftime('%Y-%m-%d')\n","  hhmmss = now.strftime('%H:%M:%S')\n","\n","  weather_list = [yymmdd, hhmmss, rain, wind]\n","\n","  print(weather_list)\n","\n","  time.sleep(8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7whhytd9jDfe","executionInfo":{"status":"ok","timestamp":1727676838175,"user_tz":-540,"elapsed":47514,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"0570872e-4159-45b7-c6b1-90b80f0e7959"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['2024-09-30', '15:13:12', '강수량0mm', '풍향 남동 5.5 m/s']\n","['2024-09-30', '15:13:21', '강수량0mm', '풍향 남동 5.5 m/s']\n","['2024-09-30', '15:13:30', '강수량0mm', '풍향 남동 5.5 m/s']\n","['2024-09-30', '15:13:40', '강수량0mm', '풍향 남동 5.5 m/s']\n","['2024-09-30', '15:13:49', '강수량0mm', '풍향 남동 5.5 m/s']\n"]}]},{"cell_type":"markdown","source":["[코드 gsm 5-11] 강수량과 풍속 크롤링하여 파일로 저장  \n","(가) : 'p'  \n","(나) : {'class':'rainfall'}  \n","(다) : 'p'  \n","(라) : {'class':'wind'}"],"metadata":{"id":"DTfJRB1Yj7XB"}},{"cell_type":"code","source":["import csv\n","import time\n","import datetime\n","import bs4\n","import urllib.request\n","\n","csvName = 'gsm_sokcho_weather2.csv'\n","nateUrl = \"https://news.nate.com/weather?areaCode=11D20401\"\n","\n","count = 5\n","while count > 0 :\n","  count -= 1\n","\n","  htmlObject = urllib.request.urlopen(nateUrl)\n","  webPage = htmlObject.read()\n","  bsObject = bs4.BeautifulSoup(webPage, 'html.parser')\n","\n","  tag = bsObject.find('div', {'class': 'right_today'})\n","  rain = tag.find('p',{'class':'rainfall'}).text\n","  wind = tag.find('p',{'class':'wind'}).text\n","\n","  now = datetime.datetime.now() + datetime.timedelta(hours=9)\n","  yymmdd = now.strftime('%Y-%m-%d')\n","  hhmmss = now.strftime('%H:%M:%S')\n","\n","  weather_list = [yymmdd, hhmmss, rain, wind]\n","\n","  f= open(csvName, 'a', newline='', encoding='utf-8-sig')\n","\n","  csvWriter = csv.writer(f)\n","  csvWriter.writerow(weather_list)\n","\n","  time.sleep(8)"],"metadata":{"id":"ef6OJTSikPVl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[코드 gsm 5-12] 순위별 책명과 가격추출  \n","(가) : \\{'class':'goods_name'}  \n","(나) : \"em\"   \n","(다) : \\{'class':'yes_b'}   \n","(라) : \\{'class':'cCont_goodsSet'}  "],"metadata":{"id":"4wDCOBYXkbIN"}},{"cell_type":"code","source":["import bs4\n","import urllib.request\n","\n","## 함수 선언 부분 ##\n","def gsm_getBookInfo(book_tag) :\n","  names = book_tag.find(\"div\", {'class':'goods_name'} )\n","  bookName = names.find(\"a\").text\n","  bookPrice = book_tag.find( \"em\", {'class':'yes_b'} ).text\n","  return[bookName, bookPrice]\n","\n","## 전역 변수 부분 ##\n","bookUrl = \"http://www.yes24.com/24/Category/Display/001001046001?ParamSortTp=05&PageNumber=1\"\n","\n","## 메인 코드 부분 ##\n","htmlObject = urllib.request.urlopen(bookUrl)\n","webPage = htmlObject.read()\n","bsObject = bs4.BeautifulSoup(webPage,'html.parser')\n","\n","tag = bsObject.find('ul', {'class':'clearfix'})\n","all_books = tag.findAll('div', {'class':'cCont_goodsSet'})\n","\n","for book in all_books:\n","  print(gsm_getBookInfo(book))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e68OGO5zkqy8","executionInfo":{"status":"ok","timestamp":1727677310158,"user_tz":-540,"elapsed":6191,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"2ed36386-3bc2-4a75-e9b1-cc5d65b3fd7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['언젠가 우리가 같은 별을 바라본다면', '10,800']\n","['모순', '11,700']\n","['영원한 천국 ', '17,820']\n","['이중 하나는 거짓말', '14,400']\n","['구의 증명', '10,800']\n","['불편한 편의점', '12,600']\n","['황금종이 1', '16,650']\n","['황금종이 2', '16,650']\n","['작별하지 않는다', '15,120']\n","['나의 돈키호테', '16,200']\n","['불편한 편의점 2', '12,600']\n","['아주 희미한 빛으로도', '15,120']\n","['홍학의 자리', '12,600']\n","['파견자들', '17,100']\n","['빛이 이끄는 곳으로', '16,920']\n","['메리골드 마음 세탁소', '13,500']\n","['아버지의 해방일지', '13,500']\n","['시한부', '15,120']\n","['회색 인간', '11,700']\n","['소년이 온다', '13,500']\n"]}]},{"cell_type":"markdown","source":["[코드 gsm 5-13] 순위별 책명과 가격 파일로 저장  \n","(가) : {'class':'goods_name'}  \n","(나) : \"em\"  \n","(다) : {'class':'yes_b'}  \n","(라) : {'class':'cCont_goodsSet'}  "],"metadata":{"id":"Bt5QNecMlv4G"}},{"cell_type":"code","source":["import bs4\n","import urllib.request\n","## 함수 선언 부분 ##\n","def gsm_getBookInfo(book_tag) :\n","  names = book_tag.find(\"div\", {'class':'goods_name'} )\n","  bookName = names.find(\"a\").text\n","  bookPrice = book_tag.find( \"em\" , {'class':'yes_b'}).text\n","  return [bookName, bookPrice]\n","\n","## 전역 변수 부분 ##\n","csvName = 'gsm_book2.csv'\n","bookUrl =\"http://www.yes24.com/24/Category/Display/001001046001?ParamSortTp=05&PageNumber=1\"\n","\n","## 메인 코드 부분 ##\n","htmlObject = urllib.request.urlopen(bookUrl)\n","webPage = htmlObject.read()\n","bsObject = bs4.BeautifulSoup(webPage, 'html.parser')\n","\n","tag = bsObject.find('ul', {'class': 'clearfix'})\n","all_books = tag.findAll('div', {'class':'cCont_goodsSet'} )\n","\n","f= open(csvName, 'a', newline='', encoding='utf-8-sig')\n","csvWriter = csv.writer(f)\n","for book in all_books :\n","  csvWriter.writerow(gsm_getBookInfo(book))\n","  # print(gsm_getBookInfo(book))"],"metadata":{"id":"ZUY2FLN4l_op"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[코드 gsm 5-14] 영화 개봉일 추출  \n","(가) : \\{'class': 'box-contents'}   \n","(나) : \\{'class': 'txt-info'}   \n","(다) : \\{'class': 'sect-movie-chart'}   \n","(라) : 'li'   "],"metadata":{"id":"lfEAJne2mwju"}},{"cell_type":"code","source":["import bs4\n","import urllib.request\n","\n","## 함수 선언 부분 ##\n","def gsm_getMovieInfo(movie_tag) :\n","  mName = movie_tag.find('div', {'class': 'box-contents'} )\n","  movieName = mName.find('a').text\n","  movieDate_Pre = mName.find('span', {'class': 'txt-info'} )\n","  movieDate = movieDate_Pre.find('strong').text\n","  return[movieName, movieDate]\n","\n","## 전역 변수 부분 ##\n","bookUrl = \"http://www.cgv.co.kr/movies/?lt=1&ft=0\"\n","\n","## 메인 코드 부분 ##\n","htmlObject = urllib.request.urlopen(bookUrl)\n","webPage = htmlObject.read()\n","bsObject = bs4.BeautifulSoup(webPage,'html.parser')\n","\n","tag = bsObject.find('div', {'class': 'sect-movie-chart'} )\n","all_movies = tag.findAll('li')\n","\n","for movie in all_movies:\n","  print(gsm_getMovieInfo(movie))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXa7a3jrnKe2","executionInfo":{"status":"ok","timestamp":1727678155327,"user_tz":-540,"elapsed":1845,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"e81aae8c-8043-4867-cbfa-1b9b9546af2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['\\n조커-폴리 아 되\\n', '\\r\\n                                2024.10.01 \\r\\n                                개봉\\nD-1\\n']\n","['\\n대도시의 사랑법\\n', '\\r\\n                                2024.10.01 \\r\\n                                개봉\\nD-1\\n']\n","['\\n베테랑2\\n', '\\r\\n                                2024.09.13 \\r\\n                                개봉\\n']\n","['\\n6시간 후 너는 죽는다\\n', '\\r\\n                                2024.10.16 \\r\\n                                개봉\\nD-16\\n']\n","['\\n임영웅ㅣ아임 히어로 더 스타디움\\n', '\\r\\n                                2024.08.28 \\r\\n                                개봉\\n']\n","['\\n와일드 로봇\\n', '\\r\\n                                2024.10.01 \\r\\n                                개봉\\nD-1\\n']\n","['\\n트랜스포머 ONE\\n', '\\r\\n                                2024.09.25 \\r\\n                                개봉\\n']\n","['\\n브레드이발소-빵스타의 탄생\\n', '\\r\\n                                2024.09.14 \\r\\n                                개봉\\n']\n","['\\n타인의 삶\\n', '\\r\\n                                2024.10.02 \\r\\n                                개봉\\nD-2\\n']\n","['\\n명탐정 코난-시한장치의 마천루\\n', '\\r\\n                                2024.10.02 \\r\\n                                개봉\\nD-2\\n']\n","['\\n비긴 어게인\\n', '\\r\\n                                2024.09.18 \\r\\n                                재개봉\\n']\n","['\\n더 커버넌트\\n', '\\r\\n                                2024.09.27 \\r\\n                                개봉\\n']\n","['\\n정국: 아이 엠 스틸\\n', '\\r\\n                                2024.09.18 \\r\\n                                개봉\\n']\n","['\\n러브 라이브! 더 스쿨 아이돌 무비\\n', '\\r\\n                                2024.10.02 \\r\\n                                개봉\\nD-2\\n']\n","['\\n극장총집편 봇치 더 록! 후편\\n', '\\r\\n                                2024.09.25 \\r\\n                                개봉\\n']\n","['\\n재즈처럼 더 무비\\n', '\\r\\n                                2024.10.02 \\r\\n                                개봉\\nD-2\\n']\n","['\\n극장판 블루 록 -에피소드 나기-\\n', '\\r\\n                                2024.08.21 \\r\\n                                개봉\\n']\n","['\\n사랑의 하츄핑\\n', '\\r\\n                                2024.08.07 \\r\\n                                개봉\\n']\n","['\\n태용: 티와이 트랙 인 시네마\\n', '\\r\\n                                2024.09.25 \\r\\n                                개봉\\n']\n"]}]},{"cell_type":"markdown","source":["[코드 gsm 5-15] 영화 개봉일 파일로 저장  \n","(가) : \\{'class': 'box-contents'}   \n","(나) : \\{'class': 'txt-info'}   \n","(다) : \\{'class': 'sect-movie-chart'}   \n","(라) : 'li'   "],"metadata":{"id":"mqT1hsDan7wY"}},{"cell_type":"code","source":["import bs4\n","import urllib.request\n","import csv\n","\n","## 함수 선언 부분 ##\n","def gsm_getMovieInfo(movie_tag) :\n","  mName = movie_tag.find('div', {'class': 'box-contents'})\n","  movieName = mName.find('a').text\n","  movieDate_Pre = mName.find('span', {'class': 'txt-info'})\n","  movieDate = movieDate_Pre.find('strong').text\n","  return [movieName, movieDate]\n","\n","## 전역 변수 부분 ##\n","csvName = 'gsm_movie2.csv'\n","bookUrl = \"http://www.cgv.co.kr/movies/?lt=1&ft=0\"\n","\n","## 메인 코드 부분 ##\n","htmlObject = urllib.request.urlopen(bookUrl)\n","webPage = htmlObject.read()\n","bsObject = bs4.BeautifulSoup(webPage, 'html.parser')\n","\n","tag = bsObject.find('div', {'class': 'sect-movie-chart'})\n","all_movies = tag.findAll('li')\n","\n","f= open(csvName, 'a', newline='', encoding='utf-8-sig')\n","csvWriter = csv.writer(f)\n","\n","for movie in all_movies :\n","  csvWriter.writerow(gsm_getMovieInfo(movie))"],"metadata":{"id":"j9XuVih6pzgZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[코드 gsm 5-16] 1위 음악명 주기적으로 추출  \n","(가) : \\{'class': 'api_subject_bx _sap_list'}  \n","(나) : \\{'class': 'detail_area'}  "],"metadata":{"id":"L08642c7pzsE"}},{"cell_type":"code","source":["import bs4\n","import urllib.request\n","import time\n","import datetime\n","\n","musicUrl1 =\"https://search.naver.com/search.naver?query=VIBE+%EC%B0%A8%ED%8A%B8&sm=mtb_clk.muc&where=nexearch\"\n","\n","count = 5\n","while count > 0 :\n","  count -= 1\n","\n","  htmlObject = urllib.request.urlopen(musicUrl1)\n","  webPage = htmlObject.read()\n","  bsObject = bs4.BeautifulSoup(webPage, 'html.parser')\n","\n","  tag_text= bsObject.find('div', {'class': 'api_subject_bx _sap_list'} )\n","  music_rank = tag_text.find('div', {'class': 'detail_area'})\n","  rank1 = music_rank.find('a').text\n","\n","  now = datetime.datetime.now() + datetime.timedelta(hours=9)\n","  yymmdd = now.strftime('%Y-%m-%d')\n","  hhmmss = now.strftime('%H:%M:%S')\n","  music_list = [yymmdd, hhmmss, rank1]\n","\n","  print(music_list)\n","\n","  time.sleep(7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gSZwGyRHqoxb","executionInfo":{"status":"ok","timestamp":1727678832155,"user_tz":-540,"elapsed":43273,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"a76e6986-34a1-4694-ea7e-ead5b1702aed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['2024-09-30', '15:46:30', 'HAPPY']\n","['2024-09-30', '15:46:38', 'HAPPY']\n","['2024-09-30', '15:46:47', 'HAPPY']\n","['2024-09-30', '15:46:56', 'HAPPY']\n","['2024-09-30', '15:47:04', 'HAPPY']\n"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","url = 'https://m.10000recipe.com/recipe/list.html'\n","\n","response = requests.get(url)\n","\n","# BeautifulSoup 객체 생성\n","soup = BeautifulSoup(response.text, 'html.parser')\n","\n","# base URL\n","base_url = 'https://m.10000recipe.com/recipe'\n","\n","# onclick 속성을 가진 div 요소 찾기\n","media_divs = soup.find_all('div', class_='media')\n","\n","urls = []\n","for media_div in media_divs:\n","    if len(urls) < 10:  # 최대 10개까지만 추가\n","        onclick_value = media_div['onclick']\n","        recipe_number = onclick_value.split(\"location.href='\")[-1].split(\"'\")[0].split('/')[-1]\n","        full_url = f\"{base_url}/{recipe_number}\"\n","        urls.append(full_url)\n","    else:\n","        break\n","\n","# CSV 파일로 저장\n","with open('recipe_data.csv', mode='w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","\n","    # 헤더 작성\n","    writer.writerow(['Type', 'Category/Step', 'Name/Description', 'Quantity'])\n","\n","    for url in urls:\n","        # 웹 페이지 요청\n","        response = requests.get(url)\n","\n","        # BeautifulSoup 객체 생성\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","\n","        # 재료와 양념 정보를 담을 리스트\n","        ingredients = []\n","\n","        # 재료와 양념 찾기\n","        for dt in soup.find_all('dt'):\n","            category = dt.get_text(strip=True)  # '재료' 또는 '양념'\n","            dd = dt.find_next_sibling('dd')  # 다음 dd 태그 찾기\n","\n","            if dd:  # dd가 None이 아닌 경우만 진행\n","                items = dd.find_all('li')  # li 태그로 있는 재료 항목들 찾기\n","\n","                for item in items:\n","                    name_div = item.find('div', class_='ingre_list_name')\n","                    quantity_span = item.find('span', class_='ingre_list_ea')\n","\n","                    # name과 quantity가 None이 아닐 때만 추가\n","                    if name_div and quantity_span:\n","                        name = name_div.get_text(strip=True)  # 재료 이름\n","                        quantity = quantity_span.get_text(strip=True)  # 재료 수량\n","                        ingredients.append({'category': category, 'name': name, 'quantity': quantity})\n","\n","        # 요리 단계를 담을 리스트\n","        steps = []\n","\n","        # 단계 정보 찾기\n","        step_list = soup.find('ul', class_='step_list st_thumb')\n","        if step_list:\n","            for step in step_list.find_all('li'):\n","                step_num = step.find('div', class_='step_list_num').get_text(strip=True)  # 단계 번호\n","                step_desc = step.find('div', class_='step_list_txt_cont').get_text(strip=True)  # 단계 설명\n","\n","                steps.append({'step': step_num, 'description': step_desc})\n","\n","        # 재료와 양념 저장\n","        for ingredient in ingredients:\n","            writer.writerow(['Ingredient', ingredient['category'], ingredient['name'], ingredient['quantity']])\n","\n","        # 요리 단계 저장\n","        for step in steps:\n","            writer.writerow(['Step', step['step'], step['description'], ''])\n","\n","print(\"데이터가 recipe_data.csv에 저장되었습니다.\")\n"],"metadata":{"id":"hjDKSNQn1AmV","executionInfo":{"status":"ok","timestamp":1727681696720,"user_tz":-540,"elapsed":14089,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a58a11d6-d049-4282-9682-fb45907b2a45"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["데이터가 recipe_data.csv에 저장되었습니다.\n"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# 초기 웹페이지 URL\n","url = 'https://m.10000recipe.com/recipe/list.html'\n","\n","# 웹 페이지 요청\n","response = requests.get(url)\n","\n","# BeautifulSoup 객체 생성\n","soup = BeautifulSoup(response.text, 'html.parser')\n","\n","# base URL\n","base_url = 'https://m.10000recipe.com/recipe'\n","\n","# onclick 속성을 가진 div 요소 찾기\n","media_divs = soup.find_all('div', class_='media')\n","\n","urls = []\n","for media_div in media_divs:\n","    if len(urls) < 10:  # 최대 10개까지만 추가\n","        onclick_value = media_div['onclick']\n","        recipe_number = onclick_value.split(\"location.href='\")[-1].split(\"'\")[0].split('/')[-1]\n","        full_url = f\"{base_url}/{recipe_number}\"\n","        urls.append(full_url)\n","    else:\n","        break\n","\n","# CSV 파일로 저장\n","with open('recipe_data1.csv', mode='w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","\n","    # 헤더 작성\n","    writer.writerow(['Type', 'Category/Step', 'Name/Description', 'Quantity'])\n","\n","    for url in urls:\n","        # 웹 페이지 요청\n","        response = requests.get(url)\n","\n","        # BeautifulSoup 객체 생성\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","\n","        # 레시피 제목 추출\n","        title_tag = soup.find('h3', class_='recipe-title')\n","        title = title_tag.get_text(strip=True) if title_tag else '제목 없음'  # 제목이 없으면 '제목 없음'\n","\n","        # 재료와 양념 정보를 담을 리스트\n","        ingredients = []\n","\n","        # 재료와 양념 찾기\n","        for dt in soup.find_all('dt'):\n","            category = dt.get_text(strip=True)  # '재료' 또는 '양념'\n","            dd = dt.find_next_sibling('dd')  # 다음 dd 태그 찾기\n","\n","            if dd:  # dd가 None이 아닌 경우만 진행\n","                items = dd.find_all('li')  # li 태그로 있는 재료 항목들 찾기\n","\n","                for item in items:\n","                    name_div = item.find('div', class_='ingre_list_name')\n","                    quantity_span = item.find('span', class_='ingre_list_ea')\n","\n","                    # name과 quantity가 None이 아닐 때만 추가\n","                    if name_div and quantity_span:\n","                        name = name_div.get_text(strip=True)  # 재료 이름\n","                        quantity = quantity_span.get_text(strip=True)  # 재료 수량\n","                        ingredients.append({'category': category, 'name': name, 'quantity': quantity})\n","\n","        # 요리 단계를 담을 리스트\n","        steps = []\n","\n","        # 단계 정보 찾기\n","        step_list = soup.find('ul', class_='step_list st_thumb')\n","        if step_list:\n","            for step in step_list.find_all('li'):\n","                step_num = step.find('div', class_='step_list_num').get_text(strip=True)  # 단계 번호\n","                step_desc = step.find('div', class_='step_list_txt_cont').get_text(strip=True)  # 단계 설명\n","\n","                steps.append({'step': step_num, 'description': step_desc})\n","\n","        # 레시피 제목을 포함한 재료와 양념 저장\n","        for ingredient in ingredients:\n","            writer.writerow(['Ingredient', ingredient['category'], ingredient['name'], ingredient['quantity']])\n","\n","        # 레시피 제목을 포함한 요리 단계 저장\n","        for step in steps:\n","            writer.writerow(['Step', step['step'], step['description'], ''])\n","\n","        # 제목 추가 (한 줄씩 비우기 위해 추가)\n","        writer.writerow(['Title', title, '', ''])\n","\n","print(\"데이터가 recipe_data1.csv에 저장되었습니다.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dgg4_R0O3AdW","executionInfo":{"status":"ok","timestamp":1727681933124,"user_tz":-540,"elapsed":13004,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"637ce8fd-6e0b-4207-f8da-3471036dcd1a"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["데이터가 recipe_data.csv에 저장되었습니다.\n"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","url = 'https://m.10000recipe.com/recipe/list.html'\n","\n","response = requests.get(url)\n","\n","# BeautifulSoup 객체 생성\n","soup = BeautifulSoup(response.text, 'html.parser')\n","\n","# base URL\n","base_url = 'https://m.10000recipe.com/recipe'\n","\n","# onclick 속성을 가진 div 요소 찾기\n","media_divs = soup.find_all('div', class_='media')\n","\n","urls = []\n","for media_div in media_divs:\n","    if len(urls) < 20:  # 최대 20개까지만 추가\n","        onclick_value = media_div['onclick']\n","        recipe_number = onclick_value.split(\"location.href='\")[-1].split(\"'\")[0].split('/')[-1]\n","        full_url = f\"{base_url}/{recipe_number}\"\n","        urls.append((recipe_number, full_url))  # 레시피 번호와 URL 함께 저장\n","    else:\n","        break\n","\n","# CSV 파일로 저장\n","with open('recipe_data2.csv', mode='w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","\n","    # 헤더 작성\n","    writer.writerow(['Recipe Number', 'Type', 'Category/Step', 'Name/Description', 'Quantity'])\n","\n","    for recipe_number, url in urls:\n","        # 웹 페이지 요청\n","        response = requests.get(url)\n","\n","        # BeautifulSoup 객체 생성\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","\n","        # 재료와 양념 정보를 담을 리스트\n","        ingredients = []\n","\n","        # 재료와 양념 찾기\n","        for dt in soup.find_all('dt'):\n","            category = dt.get_text(strip=True)  # '재료' 또는 '양념'\n","            dd = dt.find_next_sibling('dd')  # 다음 dd 태그 찾기\n","\n","            if dd:  # dd가 None이 아닌 경우만 진행\n","                items = dd.find_all('li')  # li 태그로 있는 재료 항목들 찾기\n","\n","                for item in items:\n","                    name_div = item.find('div', class_='ingre_list_name')\n","                    quantity_span = item.find('span', class_='ingre_list_ea')\n","\n","                    # name과 quantity가 None이 아닐 때만 추가\n","                    if name_div and quantity_span:\n","                        name = name_div.get_text(strip=True)  # 재료 이름\n","                        quantity = quantity_span.get_text(strip=True)  # 재료 수량\n","                        ingredients.append({'category': category, 'name': name, 'quantity': quantity})\n","\n","        # 요리 단계를 담을 리스트\n","        steps = []\n","\n","        # 단계 정보 찾기\n","        step_list = soup.find('ul', class_='step_list st_thumb')\n","        if step_list:\n","            for step in step_list.find_all('li'):\n","                step_num = step.find('div', class_='step_list_num').get_text(strip=True)  # 단계 번호\n","                step_desc = step.find('div', class_='step_list_txt_cont').get_text(strip=True)  # 단계 설명\n","\n","                steps.append({'step': step_num, 'description': step_desc})\n","\n","        # 재료와 양념 저장\n","        for ingredient in ingredients:\n","            writer.writerow([recipe_number, 'Ingredient', ingredient['category'], ingredient['name'], ingredient['quantity']])\n","\n","        # 요리 단계 저장\n","        for step in steps:\n","            writer.writerow([recipe_number, 'Step', step['step'], step['description'], ''])\n","\n","print(\"데이터가 recipe_data2.csv에 저장되었습니다.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4M0AiVV3cvq","executionInfo":{"status":"ok","timestamp":1727682289659,"user_tz":-540,"elapsed":25527,"user":{"displayName":"구승민","userId":"15085268103285628073"}},"outputId":"ff2eefe9-2c6d-4a4a-8b5e-ebbf5d98a0a5"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["데이터가 recipe_data2.csv에 저장되었습니다.\n"]}]}]}